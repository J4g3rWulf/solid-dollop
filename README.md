# ğŸ§  Rede Neural - Classificador de Lixo

> Este repositÃ³rio contÃ©m os cÃ³digos de **treinamento, avaliaÃ§Ã£o e conversÃ£o** da rede neural usada no aplicativo **RecycleApp**.

> O objetivo do modelo Ã© **classificar imagens de lixo** em mÃºltiplas categorias (ex.: garrafa de vidro, copo plÃ¡stico, papel amassado, etc.), gerando um **arquivo `.tflite` otimizado para rodar localmente no Android**, sem necessidade de internet.

> O cÃ³digo-fonte do aplicativo Android que integra este modelo estÃ¡ disponÃ­vel em:

> ğŸ‘‰ [RepositÃ³rio do RecycleApp](https://github.com/J4g3rWulf/automatic-happiness)

---

## âš™ï¸ Tecnologias utilizadas

- **Linguagem:** Python
- **Deep Learning:** TensorFlow 2 / Keras
- **PrÃ©-processamento de imagens:** Pillow (PIL)
- **MÃ©tricas e avaliaÃ§Ã£o:** scikit-learn
- **VisualizaÃ§Ã£o:** Matplotlib + Seaborn
- **Outros:**
  - Camadas de aumento de dados (data augmentation) do Keras
  - Callbacks de treinamento (`EarlyStopping`, `ReduceLROnPlateau`)
  - ConversÃ£o para TensorFlow Lite (`tf.lite.TFLiteConverter`)

---

## ğŸ§± Estrutura do projeto

```text
TCC/
â”œâ”€ images/
â”‚  â”œâ”€ train/                # Conjunto de treino + validaÃ§Ã£o (subpastas por classe)
â”‚  â”‚  â”œâ”€ glass_bottle/
â”‚  â”‚  â”œâ”€ glass_cup/
â”‚  â”‚  â”œâ”€ metal_can/
â”‚  â”‚  â”œâ”€ paper_bag/
â”‚  â”‚  â”œâ”€ paper_ball/
â”‚  â”‚  â”œâ”€ paper_milk_package/
â”‚  â”‚  â”œâ”€ paper_package/
â”‚  â”‚  â”œâ”€ plastic_bottle/
â”‚  â”‚  â”œâ”€ plastic_cup/
â”‚  â”‚  â””â”€ plastic_transparent_cup/
â”‚  â””â”€ test/                 # Conjunto de teste (mesmos nomes de pastas/classes)
â”‚
â”œâ”€ venv/                    # (Opcional) Ambiente virtual Python
â”‚
â”œâ”€ trainer_final_version.py # Script principal de treinamento da rede neural
â”œâ”€ evaluate.py              # AvaliaÃ§Ã£o em conjunto de teste + matriz de confusÃ£o
â”œâ”€ resize_images.py         # UtilitÃ¡rio para padronizar tamanho das imagens
â”œâ”€ tflite_converter.py      # ConversÃ£o do modelo Keras (.keras) para TFLite (.tflite)
â””â”€ trash_classifier_model_finetuned.keras
                            # Modelo treinado salvo em formato Keras
```

Obs.: O dataset nÃ£o Ã© versionado no GitHub por questÃµes de tamanho/licenÃ§a.
O repositÃ³rio assume que vocÃª jÃ¡ tem as pastas `images/train` e `images/test` organizadas por classe.

---

## ğŸ§ª Pipeline do modelo

A pipeline da rede neural Ã© dividida em 4 etapas principais:
1. PreparaÃ§Ã£o do dataset
2. Treinamento da CNN com focal loss
3. AvaliaÃ§Ã£o em conjunto de teste
4. ConversÃ£o para TensorFlow Lite (`.tflite`)


### 1ï¸âƒ£ PreparaÃ§Ã£o do dataset

O TensorFlow usa a funÃ§Ã£o `image_dataset_from_directory`, que espera a seguinte estrutura de pastas:

```text
images/
â”œâ”€ train/
â”‚  â”œâ”€ classe_1/
â”‚  â”œâ”€ classe_2/
â”‚  â””â”€ ...
â””â”€ test/
   â”œâ”€ classe_1/
   â”œâ”€ classe_2/
   â””â”€ ...
```

Cada subpasta representa uma classe e contÃ©m apenas imagens daquele tipo.


#### ğŸ”§ PadronizaÃ§Ã£o opcional do tamanho das imagens

  O script `resize_images.py` Ã© um utilitÃ¡rio que:
  1. Abre todas as imagens da pasta `images/train`;
  2. Corrige rotaÃ§Ã£o com base no EXIF;
  3. Converte para RGB;
  4. Redimensiona mantendo proporÃ§Ã£o (`thumbnail`);
  5. Faz padding para um tamanho fixo (`TARGET_SIZE`);
  6. Sobrescreve os arquivos originais.

Trecho central:

```text
DATA_DIR = "images/train"
TARGET_SIZE = (299, 299)

img = Image.open(filepath)
img = ImageOps.exif_transpose(img)
img = img.convert("RGB")
img.thumbnail(TARGET_SIZE, Image.Resampling.LANCZOS)
img_padded = ImageOps.pad(img, TARGET_SIZE, color="white")
img_padded.save(filepath, quality=90)
```

âš ï¸ No treinamento atual o modelo usa `IMAGE_SIZE = (256, 256)`.
O `resize_images.py` pode ser ajustado para o mesmo tamanho, se necessÃ¡rio.

---

### 2ï¸âƒ£ Treinamento da rede neural (`trainer_final_version.py`)

#### ğŸ“¥ Carregamento do dataset

O script separa automaticamente treino e validaÃ§Ã£o a partir da pasta `images/train`:

```text
IMAGE_SIZE = (256, 256)
    BATCH_SIZE = 24
    VALIDATION_SPLIT_CF = 0.1  # 10% para validaÃ§Ã£o
    DATA_DIR = "./images/train"

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    validation_split=VALIDATION_SPLIT_CF,
    subset="training",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    validation_split=VALIDATION_SPLIT_CF,
    subset="validation",
    seed=123,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE
)
```

Depois o pipeline Ã© otimizado com:

- `cache()` â€“ cache em memÃ³ria;
- `shuffle()` â€“ embaralhamento do treino;
- `map(..., num_parallel_calls=AUTOTUNE)` â€“ processamento em mÃºltiplas threads;
- `prefetch(AUTOTUNE)` â€“ sobreposiÃ§Ã£o de I/O e computaÃ§Ã£o.

#### ğŸ› Aumento de dados (data augmentation)

Para melhorar a generalizaÃ§Ã£o, o modelo aplica vÃ¡rias transformaÃ§Ãµes aleatÃ³rias apenas no treino:

```text
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
    layers.RandomTranslation(0.1, 0.1),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
    layers.RandomBrightness(0.2),
    layers.GaussianNoise(0.05)
])
```

#### ğŸ§© Arquitetura da CNN

A rede Ã© uma CNN customizada, com 5 blocos convolucionais e pooling global:

```text
model = models.Sequential([
    data_augmentation,
    layers.Rescaling(1./255, input_shape=(IMAGE_SIZE, 3)),  # NormalizaÃ§Ã£o

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(512, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.GlobalAveragePooling2D(),

    layers.Dense(512, activation='relu',
                kernel_regularizer=regularizers.l2(1e-4)),
    layers.Dropout(0.4),

    layers.Dense(len(class_names), activation='softmax')
])
```

Conceitualmente, a entrada Ã© uma imagem 256Ã—256Ã—3 (RGB normalizada para `[0,1]`).

#### ğŸ¯ FunÃ§Ã£o de perda: Focal Loss multiclasse

Em vez da entropia cruzada padrÃ£o, o projeto usa Focal Loss, mais robusta em cenÃ¡rios com classes desbalanceadas:

```text
def focal_loss_multiclass(y_true, y_pred, alpha=0.25, gamma=3.0):
    num_classes = tf.shape(y_pred)[-1]
    y_true_onehot = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)

    epsilon = tf.keras.backend.epsilon()
    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)

    pt = tf.reduce_sum(y_true_onehot * y_pred, axis=-1)
    modulating_factor = tf.pow(1. - pt, gamma)
    ce = -tf.math.log(pt)

    if isinstance(alpha, (float, int)):
        alpha_factor = alpha
    else:
        alpha_factor = tf.reduce_sum(y_true_onehot * alpha, axis=-1)

    loss = alpha_factor * modulating_factor * ce
    return tf.reduce_mean(loss)
```

O modelo Ã© compilado com:

```text
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),
    loss=focal_loss_multiclass,
    metrics=['accuracy']
)
```

#### â± Callbacks e treinamento em duas fases

O treinamento Ã© dividido em duas fases, ambas com Early Stopping e ajuste dinÃ¢mico da taxa de aprendizado:

- `EPOCHS_INITIAL = 70` â€“ treino principal
- `EPOCHS_FINE_TUNE = 35` â€“ ajuste fino com LR reduzida

Callbacks principais:

```text
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    min_lr=1e-6,
    verbose=1
)

early_stop_initial = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
```

ApÃ³s a primeira fase, o cÃ³digo mantÃ©m a learning rate atual, recompila o modelo e executa o segundo treinamento com callbacks mais agressivos.

Ao final:

```text
model.save('trash_classifier_model_finetuned.keras')
```

### 3ï¸âƒ£ AvaliaÃ§Ã£o do modelo (`evaluate.py`)

O script `evaluate.py` carrega:

- O modelo salvo (`trash_classifier_model_finetuned.keras`);
- O conjunto de teste em `./images/test/`.

```text
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 24
TEST_DIR = './images/test/'

model = tf.keras.models.load_model('trash_classifier_model_finetuned.keras', compile=False)

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    TEST_DIR,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False
)
class_names = test_ds.class_names
```

Ele calcula:

- AcurÃ¡cia e log loss por classe
- AcurÃ¡cia, precisÃ£o, recall e F1-score globais
- Matriz de confusÃ£o (visualizada via Seaborn)

Trecho principal:

```text
overall_acc = accuracy_score(y_true, y_pred)
overall_prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)
overall_rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)
overall_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)

cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
```

### 4ï¸âƒ£ ConversÃ£o para TensorFlow Lite (`tflite_converter.py`)

Por fim, o modelo Ã© convertido para um `.tflite` otimizado, que Ã© o formato usado no app Android:

```text
import tensorflow as tf

model = tf.keras.models.load_model('trash_classifier_model_finetuned.keras')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()

with open('trash_classifier_model_optimized.tflite', 'wb') as f:
    f.write(tflite_model)
```

`tf.lite.Optimize.DEFAULT` ativa otimizaÃ§Ãµes padrÃ£o do TensorFlow Lite (como quantizaÃ§Ã£o de pesos), reduzindo o tamanho do modelo e ajudando no desempenho em dispositivos mÃ³veis.

---

## â–¶ï¸ Como reproduzir o experimento localmente

### 1. Criar e ativar ambiente virtual (opcional, mas recomendado)

```text
python -m venv venv
# Windows
venv\Scripts\activate
# Linux / macOS
source venv/bin/activate
```

### 2. Instalar dependÃªncias

```text
pip install tensorflow numpy matplotlib seaborn scikit-learn pillow
```

(ou via `requirements.txt`, se criado)

### 3. Organizar o dataset

- Colocar as imagens em `images/train/<nome_da_classe>/...`
- Colocar o conjunto de teste em `images/test/<nome_da_classe>/...`
- Os nomes das pastas de `train/` e `test/` devem ser idÃªnticos.

### 4. (Opcional) Padronizar tamanho das imagens

```text
python resize_images.py
```

### 5. Treinar o modelo

```text
python trainer_final_version.py
```

Ao final, serÃ¡ gerado o arquivo:

```text
trash_classifier_model_finetuned.keras
```

### 6. Avaliar em conjunto de teste

```text
python evaluate.py
```

O script imprime mÃ©tricas no console e abre a matriz de confusÃ£o em uma janela grÃ¡fica.

### 7. Gerar modelo TFLite

```text
python tflite_converter.py
```

SaÃ­da esperada:

```text
trash_classifier_model_optimized.tflite
```

Este Ã© o arquivo que serÃ¡ usado pelo aplicativo Android (RecycleApp) via `Interpreter` do TensorFlow Lite.

---

## ğŸ“ Projeto relacionado:

**Aplicativo Android (RecycleApp â€“ classificaÃ§Ã£o de lixo com IA)**  
  ğŸ‘‰ [RepositÃ³rio do RecycleApp](https://github.com/J4g3rWulf/automatic-happiness)

### ğŸ”— IntegraÃ§Ã£o com o RecycleApp

- O arquivo `trash_classifier_model_optimized.tflite` Ã© copiado para a pasta `assets/` do app Android.
- No app, uma classe utilitÃ¡ria (`TrashClassifier.kt`) faz:
1. Carregamento da imagem a partir de uma URI;
2. Redimensionamento para 256Ã—256;
3. ConversÃ£o para `ByteBuffer` float32;
4. ExecuÃ§Ã£o do modelo TFLite;
5. Mapeamento do Ã­ndice de classe para o material exibido na interface (Vidro, Papel, PlÃ¡stico, Metal ou Indefinido).

---

## ğŸ‘¥ Equipe

Projeto de rede neural desenvolvido como parte do TCC do curso de CiÃªncia da ComputaÃ§Ã£o â€“ Universidade Veiga de Almeida, integrado ao aplicativo mÃ³vel RecycleApp.

- ResponsÃ¡veis pelo desenvolvimento do modelo de IA
  - ğŸ§‘â€ğŸ’» Davi Millan Alves
  - ğŸ§‘â€ğŸ’» Gabriel Mesquita GusmÃ£o



